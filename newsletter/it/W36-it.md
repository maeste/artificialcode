Un'altra settimana ricca di sviluppi significativi nel panorama dell'AI engineering. Ho approfondito diversi articoli importanti che meritano la tua attenzione se vuoi comprendere e formarti una prospettiva personale sull'AI Engineering e lo sviluppo di agentic AI. Non sono letture veloci, ma valgono il tempo investito per chiunque voglia padroneggiare questa tecnologia.   
Per chi √® interessato a discussioni pi√π approfondite, abbiamo trattato molti di questi argomenti in modo estensivo nel podcast di sabato (solo in italiano) su [Youtube](https://www.youtube.com/channel/UCYQgzIby7QHkXBonTWk-2Fg) e [Spotify](https://open.spotify.com/show/16dTKEEtKkIzhr1JJNMmSF?si=900902f2dca8442e).

## **üñ•Ô∏è AI Assisted Coding**

### **Punti Chiave per gli AI Engineers**

* **L'esperienza amplifica i benefici dell'AI:** Gli sviluppatori senior rilasciano 2,5 volte pi√π codice generato da AI rispetto ai junior  
* **Evoluzione degli strumenti:** I principali player stanno lanciando agenti autonomi web-based per contributi a livello di PR  
* **Comprensione fondamentale richiesta:** I LLM non sono pi√π servizi esterni; sono architettura centrale  
* **Azioni da Intraprendere:**  
  * Studiare il paper sulla mechanistic interpretability  
  * Testare gli agenti di coding web-based per task definiti

### **Cosa √® successo questa settimana?**

Il divario tra sviluppatori senior e junior nell'uso dell'assistenza AI √® diventato sorprendentemente chiaro. [L'indagine completa di Fastly su 791 sviluppatori](https://www.fastly.com/blog/senior-developers-ship-more-ai-code) rivela che gli sviluppatori senior con oltre un decennio di esperienza stanno rilasciando 2,5 volte pi√π codice generato da AI rispetto alle loro controparti junior. I numeri raccontano una storia convincente: il 32% degli sviluppatori senior riporta che oltre la met√† del loro codice rilasciato √® generato da AI, rispetto a solo il 13% degli sviluppatori junior. Non si tratta di senior pi√π esperti di tecnologia; si tratta di riconoscimento di pattern. Gli sviluppatori senior hanno sviluppato un'intuizione per quando il codice "sembra giusto" ma non lo √®, permettendo loro di individuare e correggere gli errori dell'AI pi√π efficacemente. Mentre il 59% dei senior dice che gli strumenti AI li aiutano a rilasciare pi√π velocemente, spendono anche pi√π tempo a correggere il codice generato da AI, con il 30% che riporta che modificare l'output dell'AI fa parte del nuovo flusso di lavoro.

Questo divario di esperienza crea un paradosso che [l'analisi di Crunchbase](https://news.crunchbase.com/ai/junior-talent-dilemma-sagie/) esplora in profondit√†. Le aziende sostituiscono sempre pi√π i ruoli junior con l'AI, eppure questo minaccia proprio il pipeline che crea sviluppatori senior. L'eliminazione delle posizioni junior rinuncia ai potenziali progressi dell'AI guidati dalla creativit√† e adattabilit√† dei lavoratori pi√π giovani. Le organizzazioni affrontano un dilemma tra i guadagni di efficienza a breve termine dall'automazione AI e la salute organizzativa a lungo termine che dipende dallo sviluppo dei talenti attraverso percorsi di progressione tradizionali.

Nel frattempo, il panorama degli assistenti di coding AI sta evolvendo rapidamente. [Anthropic sta sviluppando una versione web di Claude Code](https://www.testingcatalog.com/anthropic-developing-claude-code-web-version-to-rival-codex/) che competer√† direttamente con Codex di OpenAI, Jules e il web agent di Cursor, fornendo agli sviluppatori accesso diretto a un agente di coding attraverso un'interfaccia browser. La versione web includer√† integrazione GitHub e sandbox dove il codice pu√≤ essere testato in sicurezza senza setup locale. Allo stesso modo, [Jules di Google ha ricevuto aggiornamenti significativi](https://www.testingcatalog.com/googles-jules-ships-code-review-upgrades-with-pr-comments-and-more/), inclusa la capacit√† di rispondere ai commenti delle pull request, creare nuovi repository e ricevere file.

Questi agenti web-based rappresentano un cambiamento fondamentale nel modo in cui interagiamo con l'AI per il coding. A differenza degli strumenti CLI, sono progettati per task ben definiti che non richiedono decisioni architetturali. L'intervento di revisione umana √® posticipato e concentrato nel momento della PR. Non sono sostituzioni complete degli strumenti CLI ma servono scopi diversi, eccellendo in task predefiniti dove l'ambito √® chiaro e il percorso di implementazione √® diretto.

Questo ci porta a una distinzione cruciale che [Frontier AI esplora](https://frontierai.substack.com/p/ai-artists-vs-ai-engineers): AI Artists versus AI Engineers. Gli AI Artists danno ai sistemi AI controllo creativo completo, mentre gli AI Engineers operano sotto vincoli per ottimizzare qualit√† e affidabilit√†. La maggior parte dei praticanti si trova da qualche parte su uno spettro tra questi approcci, con la scelta che dipende da casi d'uso specifici e tolleranza al rischio. Come ingegneri, dobbiamo dominare la tecnologia con cui stiamo lavorando. I LLM non sono pi√π solo add-on o servizi esterni da integrare nei nostri progetti; stanno diventando sempre pi√π il cuore dei nostri sistemi.

Comprendere il loro funzionamento interno √® fondamentale. Raccomando di immergersi in questo [approfondimento completo di 54 minuti sulla mechanistic interpretability](https://www.lesswrong.com/posts/XGHf7EY3CK4KorBpw/understanding-llms-insights-from-mechanistic). Va oltre le semplici analogie come "√® solo statistica" per spiegare come i LLM basati su transformer sono predittori autoregressivi del prossimo token che eseguono task formando circuiti emergenti che combinano statistiche apprese, teste di attenzione che muovono informazioni e sub-layer MLP che immagazzinano conoscenza. Questi componenti lavorano insieme come sotto-reti specializzate che eseguono collettivamente comportamenti complessi. Potresti pensare "ma non sono un data scientist", e la mia risposta √®: vero, ma non eri nemmeno uno sviluppatore di compilatori o uno specialista JVM, eppure hai padroneggiato i dettagli dei linguaggi di programmazione che per quanto complessi fossero erano fondamentali per il successo dei tuoi progetti.

## **ü§ñ Agentic AI**

### **Punti Chiave per gli AI Engineers**

* **Pattern di design emergenti:** 21 pattern fondamentali ora documentati per agenti in produzione  
* **Sfide principali:** Gestione della memoria e valutazione delle performance rimangono critiche  
* **Ascesa dei modelli piccoli:** Modelli di azione specializzati superano i modelli generalisti grandi per task specifici  
* **Azioni da Intraprendere:**  
  * Rivedere il documento sui 21 pattern di design agentic  
  * Implementare framework di valutazione personalizzati per i tuoi casi d'uso

### **Cosa √® successo questa settimana?**

La maturazione dell'agentic AI sta accelerando, con risorse che emergono e formalizzano quello che abbiamo imparato attraverso prove ed errori. [A PM's Guide to AI Agent Architecture](https://www.productcurious.com/p/a-pms-guide-to-ai-agent-architecture) fornisce un'esplorazione dettagliata del perch√© alcuni agenti AI sembrano magici mentre altri risultano frustranti. L'architettura degli agenti √® presentata come uno stack dove ogni livello rappresenta una decisione di prodotto, enfatizzando che la capacit√† da sola non garantisce l'adozione degli utenti. Questo framework √® prezioso non solo per i product manager ma per gli sviluppatori che si avvicinano al mondo degli agenti per inquadrare correttamente i temi principali.

Per chi √® pronto ad approfondire, un [preprint completo di 400 pagine di un dirigente senior di Google](https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0) delinea i 21 pattern di design fondamentali per gli agenti AI. Questo documento fornisce esempi di codice concreti di prompt chaining, implementazione della memoria, coordinamento multi-agente e altro da applicazioni in produzione. I pattern coperti includono tutto dai protocolli di comunicazione di base degli agenti ai sistemi sofisticati di orchestrazione multi-agente. Questa risorsa serve come guida definitiva per gli ingegneri che costruiscono sistemi di agenti AI e fornisce sia le basi teoriche che pratiche necessarie per sviluppare applicazioni agentiche robuste e scalabili.

Due sfide critiche continuano a dominare lo sviluppo dell'agentic AI: gestione della memoria e valutazione delle performance. La [Context Engineering Series](https://jxnl.co/writing/2025/08/28/context-engineering-index/) esplora come agenti di coding come Claude Code e Cursor performano "context engineering" progettando portfolio di strumenti, comandi slash e architetture di sotto-agenti per aiutare i sistemi AI a scoprire le informazioni di cui hanno bisogno per performare ottimalmente. La serie dimostra che le risposte strutturate degli strumenti non sono limitate alle applicazioni di coding ma possono essere applicate attraverso le industrie, anche se richiedono maggiore focus nell'evitare l'"inquinamento del contesto" dove informazioni fuorvianti o irrilevanti degradano le capacit√† dell'AI.

Sul fronte della valutazione, [questo esame critico](https://aunhumano.com/index.php/2025/09/03/on-evaluating-agents/) enfatizza che nessuna quantit√† di valutazioni automatizzate pu√≤ sostituire l'esame manuale dei dati e la costruzione di valutazioni personalizzate per casi d'uso specifici. √à estremamente difficile e richiede molto tempo valutare gli output degli agenti quando si validano pattern di conversazione complessi, e gli sviluppatori non dovrebbero affidarsi solo a valutazioni standard. L'autore sostiene la creazione di valutazioni specifiche per dominio mantenendo l'importanza di guardare i dati reali piuttosto che solo le metriche.

Uno sviluppo intrigante √® l'ascesa dei [Small Action Models](https://tomtunguz.com/ai-skills-inversion/), che stanno diventando essenziali per l'orchestrazione efficiente degli strumenti AI. Questi modelli offrono un'alternativa costo-efficace ai modelli grandi per task specifici, esemplificando il concetto di "AI skills inversion" dove modelli specializzati pi√π piccoli superano i modelli generalisti grandi per azioni specifiche e uso di strumenti. Questi modelli focalizzati possono gestire task di routine pi√π efficientemente mentre riservano risorse computazionali e costi per task di ragionamento complessi.

Infine, [Skywork Super Agents](https://skywork.ai/) rappresenta un approccio rivoluzionario alla creazione di contenuti, trasformando prompt semplici in contenuti multimodali ricchi inclusi documenti, slide, podcast e pagine web, completi di ricerca comprensiva. La piattaforma dimostra come l'AI pu√≤ gestire workflow di creazione di contenuti complessi e multi-step che tradizionalmente richiedevano strumenti multipli e sforzo manuale significativo.

## **üíº Business and Investment**

### **Punti Chiave per gli AI Engineers**

* **Startup di agenti in rapida crescita:** Diverse aziende superano i $100M ARR  
* **Acquisizioni strategiche:** OpenAI e Atlassian fanno mosse importanti per migliorare le capacit√†  
* **Convergenza blockchain:** Principali player costruiscono infrastruttura per pagamenti di agenti  
* **Azioni da Intraprendere:**  
  * Monitorare i modelli di business delle startup di agenti  
  * Esplorare l'integrazione blockchain per meccanismi di fiducia

### **Cosa √® successo questa settimana?**

Basandoci sulla nostra discussione sui pattern dell'agentic AI, il lato business mostra una trazione impressionante. [Le startup di agenti AI stanno rapidamente scalando le operazioni](https://www.cbinsights.com/research/ai-agent-startups-top-20-revenue/), con aziende incluse Anysphere e Moveworks che ora superano i $100M ARR. Questa classifica comprensiva rivela una crescita esplosiva nel mercato degli agenti AI, con aziende che dimostrano che i sistemi AI autonomi possono generare flussi di ricavi sostanziali. Il successo di queste aziende indica una maturazione del mercato degli agenti AI e convalida la fattibilit√† commerciale di sistemi AI sofisticati che possono operare con intervento umano minimo attraverso varie funzioni aziendali.

OpenAI sta facendo mosse strategiche per rafforzare la sua posizione. [L'acquisizione da $1,1 miliardi della piattaforma di A/B testing Statsig](https://links.tldrnewsletter.com/r15gWG) rappresenta una mossa strategica per rafforzare le capacit√† di sperimentazione del prodotto mentre l'azienda scala ChatGPT a centinaia di milioni di utenti in tutto il mondo. L'acquisizione porta Vijaye Raji come CTO of Applications, indicando il focus di OpenAI sulla costruzione di infrastruttura robusta per l'ottimizzazione del prodotto e il testing dell'esperienza utente. Inoltre, [OpenAI sta sviluppando una piattaforma di hiring alimentata da AI](https://techcrunch.com/2025/09/04/openai-announces-ai-powered-hiring-platform-to-take-on-linkedin/) chiamata OpenAI Jobs Platform, programmata per il lancio entro met√† 2026, che competer√† direttamente con LinkedIn connettendo aziende e dipendenti usando capacit√† di matching AI avanzate.

[Il round di finanziamento da $350M di Sierra a una valutazione di $10B](https://sierra.ai/blog/theres-an-agent-for-that-and-it-runs-on-sierra) da Greenoaks dimostra la scala dell'opportunit√† negli agenti AI enterprise. La loro piattaforma supporta gi√† centinaia di aziende importanti e raggiunge il 90% degli americani nel retail e il 50% delle famiglie statunitensi nella sanit√†. Questa portata impressionante dimostra la fattibilit√† pratica degli agenti AI in ruoli rivolti al cliente attraverso industrie critiche.

[L'acquisizione di The Browser Company da parte di Atlassian](https://www.atlassian.com/blog/announcements/atlassian-acquires-the-browser-company) rappresenta una mossa strategica per integrare i browser Dia e Arc con i suoi strumenti di produttivit√†, creando un ecosistema comprensivo ottimizzato per i knowledge worker. L'acquisizione si concentra sull'ottimizzazione delle esperienze browser per applicazioni SaaS, incorporando capacit√† AI e migliorando le funzionalit√† di sicurezza.

Forse pi√π intrigante, [Stripe sta finanziando Tempo](https://techcrunch.com/2025/09/04/stripe-enlists-a-whos-who-including-anthropic-openai-and-paradigm-to-build-a-new-blockchain/), una nuova azienda blockchain focalizzata sul processamento di stablecoin ad alto volume, con una lista impressionante di partner inclusi Anthropic, OpenAI, Deutsche Bank, DoorDash, Mercury, Shopify e Visa. La blockchain supporter√† vari casi d'uso dai pagamenti di agenti alle rimesse, con Matt Huang di Paradigm che guida il progetto come azienda indipendente. Questa iniziativa rappresenta la convergenza della finanza tradizionale, aziende AI e tecnologia blockchain per creare infrastruttura per sistemi di pagamento di prossima generazione. L'importanza della blockchain nel garantire fiducia e privacy per le decisioni e risultati degli agenti √® qualcosa che ho esplorato in dettaglio nel mio articolo su [garantire fiducia e privacy nell'AI](https://artificialcode.substack.com/p/ensuring-trust-and-privacy-in-ai?utm_source=publication-search).

## **üîß Models and Tools evolutions that can change your workflow**

### **Punti Chiave per gli AI Engineers**

* **Rivoluzione dell'input:** L'input vocale cambia fondamentalmente i processi di pensiero  
* **Espansione dei formati audio:** NotebookLM aggiunge quattro potenti formati di overview  
* **Integrazione AI consumer:** Google Photos e Apple Siri ottengono capacit√† avanzate  
* **Azioni da Intraprendere:**  
  * Sperimentare con l'input vocale per il coding  
  * Testare Graph Transformers per dati strutturati

### **Cosa √® successo questa settimana?**

A volte i cambiamenti pi√π profondi vengono dai shift pi√π semplici. [Questa esplorazione del passaggio dalla digitazione all'input vocale](https://every.to/working-overtime/i-didn-t-know-typing-held-me-back-until-i-started-thinking-out-loud) rivela come questo cambiamento possa alterare drasticamente i processi di pensiero e aiutare le idee a fluire pi√π naturalmente e rapidamente. L'autore ha scoperto che l'input vocale ha rimosso le barriere cognitive presenti nella digitazione, permettendo un'espressione pi√π naturale di idee complesse e iterazione pi√π veloce sui concetti. Questo shift rappresenta un cambiamento fondamentale nell'interazione uomo-computer che pu√≤ sbloccare nuovi modi di lavorare con le informazioni e sviluppare idee. Confermo anche personalmente questa impressione, dato che sempre pi√π spesso uso la modalit√† volcale di chatGPT per fare brainstorming su idee nuove, sia di progetti software che di articoli da srivere

[L'introduzione di quattro nuovi formati di overview audio di NotebookLM](https://x.com/NotebookLM/status/1962949985546187120) lo trasforma da un semplice strumento di note-taking in una piattaforma comprensiva di apprendimento e ricerca. Il formato Deep Dive fornisce analisi dettagliate ed esame approfondito delle fonti, mentre Brief offre riassunti veloci di 1-2 minuti per comprensione rapida. Il formato Critique presenta feedback esperto e valutazione costruttiva di materiali come saggi o documenti di design, aiutando gli utenti a migliorare il loro lavoro. Il formato Debate crea discussioni coinvolgenti guidate da host esplorando prospettive multiple su argomenti, rendendo soggetti complessi pi√π accessibili attraverso formati conversazionali dinamici.

Le applicazioni consumer stanno rapidamente integrando capacit√† AI avanzate. [Google Photos ha integrato il suo ultimo modello di generazione video Veo 3](https://blog.google/products/photos/google-photos-create-tab-editing-tools/) nel nuovo tab Create, migliorando significativamente le capacit√† image-to-video per gli utenti. Questa integrazione rende accessibile la generazione video AI sofisticata agli utenti quotidiani attraverso un'interfaccia familiare, permettendo la trasformazione di foto statiche in contenuto video dinamico.

[Apple sta sviluppando una funzionalit√† di ricerca AI per Siri](https://www.theverge.com/news/770712/apple-ai-search-tool-siri-google-gemini) soprannominata "World Knowledge Answers" che generer√† riassunti usando risultati web e integrer√† vari formati media, potenzialmente affidandosi al modello Gemini AI di Google. L'azienda ha accordi per testare Gemini mentre considera anche i propri modelli e le offerte di Anthropic per lo sviluppo di Siri. Questo sviluppo evidenzia le relazioni complesse tra le principali aziende tech nello spazio AI, dove competizione e collaborazione spesso coesistono.

In un crossover inaspettato, [i World Models di Runway stanno attirando interesse da aziende di robotica](https://techcrunch.com/2025/09/01/why-runway-is-eyeing-the-robotics-industry-for-future-revenue-growth/) e aziende di guida autonoma che li usano per applicazioni di simulazione e training. Questo dimostra come strumenti sviluppati per applicazioni creative possano trovare applicazioni potenti in campi tecnici come lo sviluppo di sistemi autonomi. I world models forniscono ambienti di simulazione realistici che le aziende di robotica possono usare per addestrare e testare i loro sistemi in modo sicuro ed efficiente.

Infine, per chi lavora con dati strutturati, [i Graph Transformers rappresentano la prossima evoluzione delle Graph Neural Networks](https://www.unite.ai/what-every-data-scientist-should-know-about-graph-transformers-and-their-impact-on-structured-data/). Questi modelli possono processare dati strutturati attraverso meccanismi di attenzione piuttosto che message passing tradizionale. I dati aziendali tipicamente immagazzinati in tabelle relazionali possono essere ristrutturati come grafi per sbloccare insight pi√π profondi e abilitare modelli AI pi√π affidabili. Questo approccio √® particolarmente rilevante per applicazioni di sicurezza dove comprendere relazioni e dipendenze √® cruciale per rilevare anomalie e minacce.

## **üîí AI ethics and security**

### **Punti Chiave per gli AI Engineers**

* **Shift sulla privacy:** Anthropic addestra sui dati utente con scadenza opt-out  
* **Displacement lavorativo sfumato:** L'AI trasforma il lavoro piuttosto che semplice sostituzione  
* **Vulnerabilit√† di sicurezza:** Dimostrata prompt injection cross-platform  
* **Azioni da Intraprendere:**  
  * Rivedere le impostazioni di privacy dei dati prima del 28 settembre  
  * Registrarsi per Perplexity Comet via PayPal

### **Cosa √® successo questa settimana?**

Le preoccupazioni sulla privacy prendono il centro della scena mentre [Anthropic ha annunciato che inizier√† ad addestrare i suoi modelli AI usando dati di chat e coding degli utenti](https://www.theverge.com/anthropic/767507/anthropic-user-data-consumers-ai-models-training-privacy) a meno che gli utenti non facciano opt out entro il 28 settembre. Questo rappresenta un cambiamento significativo nel modo in cui le aziende AI approcciano i dati di training e la privacy degli utenti. La scadenza dell'opt-out crea urgenza per gli utenti che vogliono mantenere la privacy sulle loro interazioni, mentre solleva questioni pi√π ampie sul consenso informato e l'uso dei dati nello sviluppo AI. Per chi tiene molto alla privacy, questa notizia √® significativa, e la capacit√† di optare out fornisce un certo controllo sull'uso dei dati personali.

La conversazione su AI e occupazione continua a evolversi. [Questa analisi critica smantella il detto popolare "L'AI non prender√† il tuo lavoro, ma qualcuno che usa l'AI s√¨"](https://platforms.substack.com/p/the-many-fallacies-of-ai-wont-take), chiamandolo "vero ma completamente inutile". L'autore identifica 8 principali problemi in questa affermazione, usando l'analogia della Linea Maginot per illustrare come soluzioni apparentemente logiche possano diventare obsolete quando il sistema di riferimento cambia completamente. Grazie a [Matteo Roversi](https://substack.com/@matteoroversi) per avermi segnalato questo articolo, dato che ero abituato a usare esattamente quella frase in molte delle mie conversazioni e l‚Äôarticolo mi ha convinto a cambiarla con qualcosa come "L'AI non ti porter√† via il lavoro, lo trasformer√† cos√¨ tanto che per lavorare dovrai fare i conti con l'AI". L'articolo esplora come l'AI non sostituisca solo task individuali ma ristrutturi l'intera architettura del lavoro e delle organizzazioni. Attraverso esempi dal basket, cricket, lavoratori portuali e musicisti di sessione, l'autore dimostra come l'AI ridefinisca i workflow, ridistribuisca il potere organizzativo e possa disaccoppiare produttivit√† da compenso. Come [discusso su LinkedIn con Matteo](https://www.linkedin.com/feed/update/urn:li:activity:7369247921860517894?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7369247921860517894%2C7369267807399616513%29&replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7369247921860517894%2C7369272390486347776%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287369267807399616513%2Curn%3Ali%3Aactivity%3A7369247921860517894%29&dashReplyUrn=urn%3Ali%3Afsd_comment%3A%287369272390486347776%2Curn%3Ali%3Aactivity%3A7369247921860517894%29), mentre l'articolo stesso potrebbe non essere perfetto, sono contento che abbia aggiunto questa sfumatura al mio modo di inquadrare questo problema.

[Palantir ha introdotto Working Intelligence: The AI Optimism Project](https://x.com/PalantirTech/status/1962893370688204912), posizionando l'AI come strumento per i lavoratori americani piuttosto che una sostituzione. La campagna enfatizza applicazioni pratiche attraverso le industrie, dagli ospedali alle fabbriche, mostrando l'AI come forza per risolvere problemi reali e guidare prosperit√†. Questa iniziativa rappresenta un approccio proattivo nell'affrontare le preoccupazioni sul displacement lavorativo dell'AI, invece inquadrando la tecnologia come complementare alle capacit√† umane e focalizzata sul migliorare l'efficacia e la soddisfazione del lavoro piuttosto che la sostituzione.

Sul fronte della sicurezza, [AgentHopper rappresenta un proof-of-concept innovativo di virus AI](https://embracethered.com/blog/posts/2025/agenthopper-a-poc-ai-virus/) che dimostra come la prompt injection possa essere sfruttata come meccanismo potente per colpire agenti di coding specifici attraverso piattaforme multiple. Creato per mostrare che la prompt injection condizionale pu√≤ operare attraverso diversi agenti AI, AgentHopper funziona infettando un agente, che poi scarica il payload, scansiona repository Git, li infetta con payload di prompt injection universali e spinge cambiamenti su GitHub. Quando altri sviluppatori scaricano il codice infetto, i loro agenti diventano compromessi, creando un meccanismo di propagazione virale. Il virus ha colpito vulnerabilit√† in GitHub Copilot, Amp Code, Amazon Q Developer e AWS Kiro, anche se tutte queste vulnerabilit√† sono state da allora patchate.

Infine, [Perplexity ha annunciato il rollout del suo browser Comet a tutti gli studenti](https://link.mail.beehiiv.com/ss/c/u001.dSnm3kaGd0BkNqLYPjeMf_opy6mIvpZNWVg6eiOhxpKgS8ljhEr8MihDuee9oKFuNKAnMqNtaM4a7AGpfWzcBVFipvDsQZxFVk1ZuU_J3NFfZhYJGLlGYTO4haIxB4UGUH2tBbdwN1cMPswHApIOjUrfthov3pbMccSy4buEgmjTTKudwthdJnYlq6mEySZjXsJIRFdN9k4GtTrHMXDNzQFdE_Qo5SnF-welsXXISOTQ1EpUugn2AZi0YgxDA3BIHBXj5ko9TJyi2whYPr0Lcg/4jm/3RoJ4qA0RFyx1Ud5tq1qtg/h30/h001.XvrTmfuJjz97_kLjz8ESCyfKDkY-f5I0eVj0EIqxj1I), insieme a una partnership con PayPal per fornire agli utenti accesso anticipato alla piattaforma. **Per chi ha un account PayPal, puoi accedere a un anno di uso gratuito del browser AI di Perplexity, Comet**. Raccomando di registrarsi\! Il browser √® progettato specificamente per educazione e ricerca, integrando capacit√† AI native per aiutare gli studenti a navigare, ricercare e sintetizzare informazioni pi√π efficacemente.
