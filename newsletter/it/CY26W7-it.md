# Codice Artificiale - Settimana 7 del 2026

Uno dei motivi, forse il principale, per cui ho iniziato a scrivere questa newsletter e poi a registrare [Risorse Artificiali](https://risorseartificiali.com) è l'esigenza che ho sentito di partecipare alla divulgazione AI. E quell'esigenza nasce dal fatto che penso che l'AI (e in particolare l'AGI) ed i suoi impatti sul business, società e lavoro siano troppo trascurati. Forse non da tutti, ma da tanti si sente fare un esercizio di negazione, più o meno argomentata, spesso in un vacuo tentativo di ridicolizzarla (vedi tutti i post di questa settimana sull'autolavaggio). Ho già visto succedere questa cosa molto di recente, e ringrazio Matt Shumer per aver avuto il coraggio di fare quel paragone che mi gira in testa da tanto tempo tra l'AGI ed il Covid. Ne sono stato lontano da quel paragone, per non dare all'AGI un'accezione negativa (tutto sono fuorché un doomer), ma vedo gli stessi meccanismi di negazione, forse dettati dalla paura, ma molto più dall'ignoranza. Come per il Covid (e credetemi, io vivo a Cremona, la provincia più colpita e con più morti del 2020) fino a che non si sono visti gli ospedali da campo nessuno ci ha creduto per davvero. Non sapete quante volte ho sentito dire "è una cosa della Cina", "sarà la solita brutta influenza". Ecco, l'AGI sta arrivando, non è una cosa degli altri, non è la solita tecnologia. Cambierà molti dei lavori che conosciamo. Cambierà la società. E io mi auguro che non faccia i danni del Covid, ma dobbiamo farci trovare preparati per controllare il cambiamento e non esserne controllati.

E non lo dico io, lo dicono tutti gli scienziati e le persone più influenti di questo campo. Persone che hanno visibilità su cosa sta accadendo nei grandi laboratori. Oggi, non tra 15 anni.

Qualche settimana fa ho intervistato Alessandro Maserati sul [podcast](https://risorseartificiali.com). E lui diceva: "Allora secondo me è molto sottovalutato nel dibattito pubblico il fatto che stiamo parlando già solo del fatto che sia raggiungibile l'AGI, no? Già solo quello dovrebbe, come dire, popolare tutte le prime pagine, tutti i giornali, non dovremmo parlare di nient'altro." Sottoscrivo, parola per parola.

Ieri ho commentato un [post su Linkedin](https://www.linkedin.com/posts/luca-baroncini-b4b1a1b6_%C3%A8-un-po-di-tempo-che-non-scrivo-qui-leggo-activity-7428362980020580352-VetI) che faceva un appello di cuore. Sottoscrivo anche quello, e mi fa sperare che ci sia una presa di coscienza almeno tra chi lavora in questo settore.

Sotto trovate le news di questa settimana, la prima sezione idealmente continua questa introduzione, ma anche nelle altre se leggete con occhio attento troverete l'evoluzione che corre in quella direzione. Se mi seguite da un po' e avete letto le mie newsletter in modo critico per voi non sarà una novità. Se mi posso permettere, cominciate a parlarne anche all'amico meno addentro a questo mondo, senza un'accezione negativa. Questa è una tecnologia, uno strumento, e come tutti gli strumenti va solo usata bene. Ma prima ancora non va negata, anzi va capita oggi per usarla al meglio domani.

---

## Business e società

### I Takeaways per gli AI Engineers

- **Takeaway 1:** I leader AI parlano di AGI come fait accompli - Amodei (90% confidenza), Suleyman (18 mesi per performance umane): non è più "se", ma "quando". Quello che vedono nei lab oggi determina queste previsioni
- **Takeaway 2:** "Something Big Is Happening" va letto e condiviso - Non è clickbait, è realista. La preparazione è un dovere professionale verso sé stessi e chi ci circonda
- **Takeaway 3:** La disruption del lavoro white-collar è in corso - Non tra 15 anni, ma su timeline di 1-5 anni per il 50% delle posizioni entry-level

- **Action Items:**
  - Leggi "Something Big Is Happening" e condividilo - Se lo hai già letto, rileggilo. Poi fallo leggere a qualcuno meno addentro ai temi AI
  - Prepara un piano di adattamento professionale - Non aspettare: integra AI nel lavoro quotidiano, costruisci resilienza finanziaria, cultiva adattabilità

### Cosa succede questa settimana?

Di solito questa è l'ultima sezione della mia newsletter. Ma non oggi, perché le notizie che riporto sono tutte a dire che l'AGI sta arrivando e come avete letto nell'introduzione ritengo sia giunto il momento di prenderne coscienza.

Ma andiamo con ordine. L'articolo "Something Big is Happening" lo avrete probabilmente già letto, o almeno visto citare da qualcuno questa settimana. Di certo è sulla bocca di tutti quelli che si occupano a diverso titolo di AI. Bene, se non lo avete letto leggetelo e rileggetelo, se lo avete già letto rileggetelo di nuovo...e poi fatelo leggere a qualcuno che è meno addentro di noi nel tema. Non esagera, non è click bait, è realista. Farsi trovare preparati è una necessità ed un dovere.

Dario Amodei ha parlato nel podcast di Dwarkesh Patel. Ed ha ribadito molte delle cose che ha detto in panel con Demis Hassabis un paio di settimane fa. Ovvero che il punto non è SE arriverà un "Country of geniuses in a data center", ma quando. Perché il SE è ad un livello di confidenza del 90% (da bravo scienziato, non da nulla per certo, ma esprime livelli di confidenza). E Amodei è più scienziato che CEO, e forse una delle menti più brillanti del mondo, sicuramente del settore.

Mustafa Suleyman, responsabile AI di Microsoft - non lo smanettone della porta accanto - invece parla di AI che raggiungerà performance umana in 18 mesi e che la maggior parte di attività al computer sarà completamente automatizzata. Ovvero molti dei lavori da "colletti bianchi" non ci saranno più, almeno per come li conosciamo oggi.

Queste persone hanno visibilità su cose che accadono dentro i laboratori e se loro (e altri) continuano a parlare di queste cose è perché le stanno vedendo accadere oggi. Oggi, non tra 15 anni.

Ho riportato anche altri articoli, per darvi un quadro più completo.

### I link della settimana

- **[Something Big Is Happening](https://shumer.dev/something-big-is-happening)** - Timeline 1-5 anni per 50% posizioni entry-level white-collar, preparazione urgente

- **[AI Skepticism: Career Killer](https://leaddev.com/career-development/ai-skepticism-is-a-quiet-career-killer)** - La resistenza all'adozione AI sta diventando una responsabilità professionale

- **[AI Champions](https://leaddev.com/ai/ai-champions-are-the-key-to-engineering-adoption)** - Tecnologi influenti nei team guidano l'implementazione AI di successo

- **[Dario Amodei: Dwarkesh Podcast](https://www.dwarkesh.com/p/dario-amodei-2)** - "Country of geniuses in a data center" entro 1-3 anni, 90% confidenza

- **[Anthropic Series G](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation)** - $30B funding, $380B valuation, $14B revenue run-rate

- **[Mustafa Suleyman: Fortune](https://fortune.com/2026/02/13/when-will-ai-kill-white-collar-office-jobs-18-months-microsoft-mustafa-suleyman/)** - AI a performance umana in 18 mesi, automazione lavori white-collar

---

## Novità e ricerca nei modelli AI

### I Takeaways per gli AI Engineers

- **Takeaway 1:** Gemini 3 Deep Think stabilisce nuovi record - Con 84.6% su ARC-AGI-2 e 48.4% su Humanity's Last Exam, i benchmark dimostrano progressi significativi verso capacità di reasoning sempre più vicine all'AGI
- **Takeaway 2:** L'AI open-source cinese sta cambiando le regole del gioco - Modelli come MiniMax M2.5, Step 3.5 Flash e GLM-5 offrono performance near-SOTA a 1/10-1/20 del costo dei competitor americani, rendendo l'AI avanzata accessibile a tutti
- **Takeaway 3:** La competizione si sposta su velocità ed efficienza - Dalle versioni "flash" e "lightning" all'esecuzione su hardware Cerebras, il focus non è più solo sulla qualità ma su renderne l'uso pratico ed economico

- **Action Items:**
  - Testa un modello cinese open-source - Prova MiniMax M2.5 o Step 3.5 Flash: a 1/20 del costo di Claude, vale la pena esplorare alternative economiche per workload ripetitivi
  - Guarda le demo di Seedance 2.0 e Qwen-Image - I link di questa settimana mostrano qualità video e immagini che fino a poco tempo fa sembravano impossibili

### Cosa succede questa settimana?

Ci sono tante novità nei modelli questa settimana, ma non posso che partire dall'ultima versione di Gemini 3 Deep Think. I benchmark che potete verificare nel link che riporto sono più che impressionanti. Raccontano di una AGI che si avvicina a grandi passi. Indubbiamente i benchmark non sempre raccontano tutta la verità e alzano le aspettative, ma in ogni caso i miglioramenti dalle versioni precedenti sono impressionanti e fanno il paio con i discorsi di Amodei ed altri su un avvicinamento all'AGI e gli impatti che può avere su lavoro e società.

Benché i risultati del modello di DeepMind abbiano preso l'onore della ribalta, non sono certo gli unici per quanto riguarda l'aggiornamento dei modelli. Da sola l'evoluzione di GPT-5.3 Codex Spark, una versione più piccola e super veloce dell'ultimo nato in casa OpenAI, sarebbe una grande notizia sia per la velocità raggiunta che per essere la prima a girare su hardware Cerebras. Ma c'è molto che arriva anche dalla Cina con tre modelli SOTA a prezzi molto bassi e ottimi benchmark, che li avvicinano ai modelli top americani ad 1/10 del costo. I modelli cinesi sembrano ridurre il gap con quelli SOTA delle big tech, pur rimanendo qualche mese indietro, ma il fattore costi e il fatto che siano open li rende comunque molto interessanti. In fondo quando qualche mese fa è uscito Opus 4.1 e poi 4.5 abbiamo gridato al miracolo, e oggi i modelli GLM, MiniMax, e Step praticamente eguagliano quelle performance comunque incredibili, anche se noi stiamo già guardando a 4.6 e oltre.

Infine riporto due notizie e qualche link di demo per un modello per immagini (Qwen-Image, così piccolo da girare su computer da gamer o Mac Mini) e per Video. Tratto meno questi tipi di modelli qui in newsletter, ma i progressi incredibili li potete vedere da soli se seguite i link sotto.

### I link della settimana

- **[Qwen-Image-2.0](https://qwenlm.github.io/blog/qwen-image-2-0/)** - Generazione immagini con risoluzione nativa 2K, rendering testo avanzato e prompt fino a 1K token

- **[Seedance 2.0](https://www.doubao.com/video/)** - Text-to-video di ByteDance con movimento naturale e micro-dettagli impressionanti

- **[Step 3.5 Flash](https://static.stepfun.com/blog/step-3.5-flash/)** - Modello sparse 196B che attiva solo 11B parametri per token, 100-350 tok/s

- **[GPT-5.3 Codex Spark](https://openai.com/index/introducing-gpt-5-3-codex-spark/)** - Nuovo modello OpenAI avanzato per coding e reasoning, primo su hardware Cerebras

- **[GLM-5](https://z.ai/blog/glm-5)** - Ultimo modello Zhipu AI con reasoning migliorato, parte dell'ondata di modelli cinesi competitive

- **[Gemini 3 Deep Think](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/)** - Record sui benchmark: 84.6% ARC-AGI-2, 48.4% Humanity's Last Exam, 3455 Elo Codeforces

- **[MiniMax M2.5](https://venturebeat.com/technology/minimaxs-new-open-m2-5-and-m2-5-lightning-near-state-of-the-art-while)** - Open-source frontier: SWE-Bench 80.2%, 1/20 del costo di Claude Opus 4.6

---

## Agentic AI

### I Takeaways per gli AI Engineers

- **Takeaway 1:** OpenClaw segna un cambio di paradigma - Da prompt espliciti (chat) a contesto iniettato da flussi dati con tool per eseguire azioni: i modelli con accesso a dati real-time definiscono strategie e agiscono autonomamente
- **Takeaway 2:** Tre trend si consolidano: Skills, Sandbox, Swarm - Skills per workflow riutilizzabili, Sandbox per esecuzione sicura, Swarm per parallelizzare task complessi con decine di agenti

- **Action Items:**
  - Ascolta l'intervista di Peter Steinberger su Lex Fridman - Spiega meglio di chiunque altro il passaggio da chat-based a context-driven agent behavior
  - Esplora il corso A2A su deeplearning.ai e il progetto GitHub - Il protocollo sta diventando standard per far comunicare agenti tra framework diversi

### Cosa succede questa settimana?

Se i modelli continuano ad evolvere e migliorare continuamente, quello che sta succedendo nel mondo degli agenti è un vero e proprio "aha moment", capace di ridefinire le aspettative che abbiamo dagli agenti intelligenti. Mi riferisco ovviamente ad OpenClaw e a quanto stia facendo capire come questi modelli con un ampio accesso a dati in tempo reale siano in grado di definire strategie di comportamento e compiere azioni. Niente di magico o di inaspettato per chi osserva i cambiamenti in corso, è una naturale evoluzione di quello che abbiamo visto succedere negli ultimi due anni. Quello che accade in agenti autonomi e proattivi come OpenClaw è lo spostamento dell'iterazione da quella basata su un prompt esplicito (la chat) ad un contesto iniettato da flussi di dati che creano prompt impliciti e tool che permettono di eseguire azioni. Lo spiega, ovviamente molto meglio di me, l'autore di OpenClaw Peter Steinberger in intervista da Lex Fridman. Ascoltatela.

Altri tre trend chiarissimi nel mondo degli agenti in questo periodo sono le Skills, le sandbox, e sub-agenti paralleli spesso detti swarm.
Iniziamo dalle Skills, che altro non sono che insiemi di istruzioni e script riutilizzabili per costruire workflow. Ideate e lanciate da Anthropic, sono state adottate da tutti, e questa settimana OpenAI ne ha sottolineato l'importanza anche nelle loro API.
Per quanto riguarda le sandbox, vale la pena leggere l'articolo di LangChain perché chiarisce molti concetti a riguardo.
Di Agent Swarm stanno parlando un po' tutti, Anthropic, MiniMax, Z.AI con GLM 5.0. Riporto qui però un articolo di Kimi, tra i primi a parlare di Agent Swarm, che è di notevole interesse perché affronta il tema di swarm molto grandi.

Vi lascio con l'invito di dare un'occhiata al corso su A2A recentemente lanciato da deeplearning.ai. E ovviamente date un'occhiata al progetto A2A su GitHub dove io e il mio team siamo personalmente coinvolti.

### I link della settimana

- **[A2A Protocol](https://twitter.com/AndrewYNg)** - Standard per discovery e comunicazione tra framework di agenti, con corso su deeplearning.ai

- **[Kimi Agent Swarm](https://www.kimi.com/blog/agent-swarm.html)** - Fino a 100 sub-agenti paralleli, 4.5x più veloce dell'esecuzione sequenziale

- **[OpenAI Skills API](https://developers.openai.com/cookbook/examples/skills_in_api/)** - Bundle riutilizzabili di istruzioni, script e assets per workflow ripetibili

- **[Pattern di connessione sandbox](https://links.tldrnewsletter.com/tUGxss)** - Due pattern architetturali per integrare agenti con sandbox di esecuzione

- **[Lex Fridman: Peter Steinberger](https://www.youtube.com/watch?v=YFjfBk8HI5o)** - Intervista al creatore di OpenClaw su agentic engineering e futuro dello sviluppo software

---

## AI Assisted Coding

### I Takeaways per gli AI Engineers

- **Takeaway 1:** "Libraries are over, LLMs are the new compiler" - La provocazione di Karpathy punta a software più fluido con meno dipendenze: estrarre solo ciò che serve da librerie monolitiche tramite agenti AI
- **Takeaway 2:** La memoria persistente diventa priority - Claude-mem dimostra che "done is better than perfect": anche se imperfetto, il tentativo di dare memoria di lungo termine agli agenti di coding è fondamentale
- **Takeaway 3:** La durata dei task come metrica di progresso verso AGI - Cursor arriva a 24+ ore di task autonomi: se la lunghezza dei task completabili con errore accettabile cresce, ci stiamo avvicinando all'AGI

- **Action Items:**
  - Leggi il thread di Karpathy e prova DeepWiki via MCP - Sostituisci "github" con "deepwiki" nell'URL di un repo per capire il potenziale
  - Installa Claude-mem e testalo su un progetto reale - Valuta se la memoria persistente migliora la tua produttività con Claude Code

### Cosa succede questa settimana?

L'articolo più rilevante questa settimana in tema di AI assisted coding è senza dubbio quello di Karpathy. Come sempre in modo abbastanza sintetico tocca tanti punti interessanti. In primis l'uso di DeepWiki tramite MCP per dare un contesto ricco e di qualità all'LLM relativamente al repository su cui si sta lavorando. Uso spesso DeepWiki per generare automaticamente il wiki con l'architettura del progetto per aiutarmi a capire meglio nuovi progetti. Usarlo come MCP server è geniale e sposta il confine di comprensione e di gestione di progetti complessi. Ma nell'articolo Andrej sgancia una vera bomba, spingendosi a dire "Libraries are over, LLMs are the new compiler". Concordo sulla sua volontà di ottenere un software più fluido e con meno dipendenze, anche se questo può mettere in crisi alcuni modelli di licenza open source e di proprietà intellettuale. Leggete quell'articolo, è pieno di spunti pratici, ma anche di spunti di riflessione.

Claude-mem sta evolvendo molto, e merita di essere provato ed approfondito. È un tentativo, anche se a mio avviso non perfetto, di dare agli agenti di coding una memoria di lungo termine che vada al di là della sessione. È qualcosa di cui sicuramente c'è bisogno, che ha anche una grande complessità. Come detto, non è secondo me perfetto, ma in quest'epoca di AI e codice generato e migliorato alla velocità della luce, comincio a pensare che "done is better than perfect". Ovvero è un buon inizio che può ispirare altri a fare ancora meglio. Da provare sia nei coding agents (tipo Claude appunto a cui si ispira il nome) che in agenti più generici tipo OpenClaw.

La velocità è sicuramente un tema, come dicevo nel capitolo precedente, e Anthropic mette a disposizione (a costo) una modalità veloce per Opus. Intanto Cursor lancia i Long-running Agents con task fino a 24 ore. E immagino che ricordiate che uno dei parametri più importanti per misurare l'impatto degli agenti intelligenti in un certo settore sia la lunghezza dei task che sono in grado di svolgere con un fattore di errore accettabile. 24 ore comincia a far pensare a qualcosa che sempre di più si avvicina all'AGI. Tema che ritorna anche in questa sezione.

### I link della settimana

- **[Claude Code Fast Mode](https://code.claude.com/docs/en/fast-mode)** - Opus 4.6 2.5x più veloce con `/fast`, pricing $30/150 MTok

- **[Claude-Mem](https://github.com/thedotmack/claude-mem)** - Plugin memoria persistente per Claude Code con web viewer e ricerca ibrida

- **[Cursor Long-Running Agents](https://cursor.com/blog/long-running-agents)** - Agenti autonomi fino a 24+ ore con planning e verifica multi-agente

- **[Karpathy: DeepWiki e MCP](https://x.com/karpathy/status/2021633574089416993)** - "Libraries are over, LLMs are the new compiler" - software più fluido e malleabile
