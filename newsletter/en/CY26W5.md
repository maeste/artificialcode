This newsletter issue isn't particularly long, but it's dense. The links and stories I report below deserve careful reading and some deeper exploration. But before highlighting my three top stories discussed below, let me recommend you dive into what I consider the most relevant topic of the week, and perhaps of all of January.

Like last year, there was a panel/discussion at the World Economic Forum between Demis Hassabis and Dario Amodei talking about AGI (Artificial General Intelligence), or more precisely about the world after AGI. I recommend spending 30 minutes on the complete [YouTube Video](https://www.youtube.com/watch?v=02YLwsCKUww) because the scope of what they say should interest anyone, not just AI Engineers, but also economists and politicians. We discussed it on the [Risorse Artificiali podcast](https://risorseartificiali.com) on Saturday, if you'd like to hear our opinion and reflect on it a bit.

As an extension of this, I recommend you get comfortable and read Amodei's annual article (it's almost a book, but worth it) on these topics: [The Adolescence of Technology - Dario Amodei Essay](https://www.darioamodei.com/essay/the-adolescence-of-technology).

Returning to the links and topics covered below, let me highlight three:

- The advent of OpenClaw... interesting mainly as a window into the future of what (this year) agents will do for us. A taste of AGI that makes you understand why Hassabis and Amodei's discussions are fundamental to address NOW!
- Agentic coding is the most important paradigm shift in code development of the last 20 years. Andrej Karpathy dixit.
- Google is expanding its AI influence: Gemini on all phones, in Chrome, self-produced TPUs, customers "stolen" from OpenAI.

Good reading! Any feedback is more than welcome, as always.

---

## AI Model News and Research

### Takeaways for AI Engineers

- **Takeaway 1:** 2026 marks the affirmation of two parallel trends: visual reasoning capabilities integrated into CoT and multi-agent processes both internal and external to models
- **Takeaway 2:** Visual models are evolving toward "thinking with images" similar to humans, using diagrams and sketches to support reasoning
- **Takeaway 3:** Robotics is about to reach its "aha moment" in the next 18 months, driven by convergence of hardware like Helix 02 and world models like Genie

- **Action Items:**
  - Experiment with Genie in Google Labs to understand the potential of interactive world models
  - Study how to integrate visual reasoning into your organization's AI development processes

### What's happening this week?

There's a common thread in the first three model-related stories this week: visual capability as an integral part of reasoning is the trend emerging in this early part of the year and could mark another turning point for multimodal LLMs. I believe 2026 will see two major trends establish themselves:

- Agent processes both internal and external to models: both Kimi K2.5 and Gemini are pushing toward orchestrating and parallelizing multiple agents
- Model multimodality used also in CoT, meaning in thinking processes. If you think about it, it's a natural evolution from token-only CoT, exactly as we happen to make ourselves a sketch or diagram to help us think, so models are starting and will do this more and more

There's a third evident trend this week in research and practice. A trend that will have its "aha moment" soon, let's say in the next 18 months. I'm talking about robotics, and this week we see it both with hardware like the impressive Helix 02 and in software with world models dominating research papers in recent months. But Google goes beyond by letting us try their Genie, a state-of-the-art world model available in Google Labs. Give it a spin.

### This week's links

- **[Kimi K2.5: Visual Agentic Intelligence](https://www.kimi.com/blog/kimi-k2-5.html)** - Moonshot AI introduces the most powerful open-source model with 15T visual-textual tokens, agent swarm up to 100 sub-agents and up to 4.5x time reduction.
- **[Google launches Agentic Vision in Gemini 3 Flash](https://www.testingcatalog.com/google-launches-agentic-vision-in-gemini-3-flash/)** - Iterative Think-Act-Observe approach with code execution for auto zoom, image annotation and complex table parsing.
- **[Visual Models for Reasoning Like Humans](https://github.com/thuml/Reasoning-Visual-World)** - Unified multimodal model using visual generation as part of chain-of-thought for human-like reasoning.
- **[Introducing Helix 02: Full-Body Autonomy](https://www.figure.ai/news/helix-02)** - Single neural system controlling the entire body from pixels, loco-manipulative autonomy in complete kitchen for 4 minutes without human intervention.
- **[Google DeepMind's Project Genie Now Live](https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/)** - Interactive world-building prototype available for Google AI Ultra subscribers, creates virtual environments with real physics and dynamics.

---

## Agentic AI

### Takeaways for AI Engineers

- **Takeaway 1:** OpenClaw represents the frontier of general-purpose agents capable of operating on any desktop task, but requires extreme caution: VM sandboxing and isolated accounts are essential
- **Takeaway 2:** Big tech are implementing agentic AI with more controlled approaches: Anthropic with integrated MCP apps in Claude, Google with Gemini in Chrome
- **Takeaway 3:** The trend toward autonomous agents is unstoppable, but security remains the bottleneck: with great power comes great responsibility

- **Action Items:**
  - Evaluate adopting AI agents in your workflow starting with controlled approaches like Claude's MCP apps
  - If you experiment with general-purpose agents like OpenClaw, always create an isolated environment with VM and dedicated accounts

### What's happening this week?

This week I can't start this section without talking about OpenClaw, formerly known as Clawd.bot and molt.bot (see [here](https://openclaw.ai/blog/introducing-openclaw) the story of how and why they changed the project name 3 times in 10 days). What is it? An agent similar in some ways to coding agents like claude-code and Codex, but capable of performing any task and speaking with you through Telegram or WhatsApp. And when I say any task, I mean practically anything you can do with your PC.

I tried it and was able to send it requests (on Telegram while away from home) like: "check my mail, take those arriving from this newsletter and produce a summary document with all links mentioned. Then search the web for the most discussed news/links and create a section in the document with the 5 most relevant and 5 most controversial. When you're done send me a summary on Telegram"... and wow, after 5 minutes it had done everything.

At the moment it's not a tool for everyone (with great power comes great responsibility, said the most famous uncle in the American comics industry): it's a tool for tinkerers and especially for those who know what they're doing, because to do all these things you have to give it access to your mail, your entire computer, your tools... and it works uncontrolled, potentially causing great damage or exposing you to prompt injection risks from malicious actors. I ran everything on an isolated virtual machine, accessing accounts I created only for the test. But the experiment is fascinating, and shows what will happen soon with delegating a significant part of work to agents, as those using coding agents extensively know, not just for coding (we'll talk about this next week in the [podcast](https://risorseartificiali.com).

On the other hand, big tech are going in this direction, with more caution to avoid the risks mentioned above: Anthropic with MCP apps in Claude, Google with tight Gemini integration in Chrome (see links below).

I close this part with a promise: if someone shows interest with comments or via social media, I'll write a step-by-step article to configure a virtual machine to isolate OpenClaw as much as possible.

### This week's links

- **[Anthropic Integrates Interactive MCP Apps into Claude](https://www.testingcatalog.com/anthropic-integrates-interactive-mcp-apps-into-claude/)** - Interactive MCP apps for Asana, Slack, Figma and Box directly in Claude with live integrated experiences and open standards.
- **[Kimi Agent SDK](https://github.com/MoonshotAI/kimi-agent-sdk)** - Programmatic interface for Kimi CLI with native clients, multi-turn conversation automation and custom tools.
- **[Chrome: The browser you love, reimagined with AI](https://blog.google/products-and-platforms/products/chrome/chrome-reimagined-with-ai/)** - New vision of Chrome with native AI, intelligent automation and advanced contextual understanding.
- **[Google begins rolling out Chrome's "Auto Browse" AI agent today](https://arstechnica.com/google/2026/01/google-begins-rolling-out-chromes-auto-browse-ai-agent-today/)** - Autonomous browsing agent in split-screen, image editing with Nano Banana and AI page manipulation.
- **[OpenClaw AI](https://openclaw.ai/)** - Emerging platform for autonomous AI agents with advanced orchestration and multi-system integration.

---

## AI Assisted Coding

### Takeaways for AI Engineers

- **Takeaway 1:** Agentic coding represents the biggest paradigm shift in software development of the last 20 years, going beyond simple code completion to true capability expansion
- **Takeaway 2:** With coding agents we speak more of expansion than acceleration: delegating to AI you end up doing more things, not just the same things faster
- **Takeaway 3:** Workplace isolation becomes crucial: local sandboxes like Claude-code's `/sandbox` and isolated cloud solutions are the answer to security needs

- **Action Items:**
  - If you don't use a coding agent yet, create an isolated sandbox and try: it's a paradigm shift from which there's no turning back
  - Evaluate cloud solutions for isolated development environments when local sandbox is insufficient for your needs

### What's happening this week?

I connect back to what I was saying before talking about OpenClaw: with agents, whether general purpose or pure coding, it's becoming increasingly important to isolate the work environment. And while locally sandboxing that isolates the filesystem (for example claude-code has a native `/sandbox` command for this) and development context are a good solution, solutions for creating isolated development environments in cloud are also gaining ground. Personally I haven't felt a strong need yet, but the article I report below made me "itch" in this sense.

The other link I want to highlight is Andrej Karpathy's article/long tweet, which as you know is one of my favorite voices in the AI world. Karpathy says many significant things that I invite you to read (it takes 3 minutes), but those that struck me most and that I fully subscribe to, having had identical experiences:

- Agentic coding (attention not AI code completion or lesser things, we're talking about agentic coding with things like claude-code or Codex or similar) is the biggest paradigm shift in code development we've experienced in the last 20 years. Nothing to add.
- More than acceleration we can speak of expansion. That is, delegating and accelerating many tasks to AI you end up doing more things and not simply the same things faster
- With coding agents (especially when used also for other tasks, I add) you get the feeling of what AGI will be

You're not using a coding agent yet? Courage, make your sandbox and try it, as Karpathy says it's the biggest paradigm shift of the last 20 years, and from which there's no turning back.

### This week's links

- **[The surprising attention on sprites, exe.dev, and shellbox](https://lalitm.com/trying-sprites-exedev-shellbox/)** - New Linux VPS services optimized for Claude Code, handle web service sharing and end-to-end stack without configuring VMs, containers or certificates.
- **[Agent Trace: Capturing the Context Graph of Code](https://cognition.ai/blog/agent-trace)** - Open vendor-neutral spec to record AI contributions with human authorship, makes development legible and enables management data-driven dashboards.
- **[Management as AI superpower](https://www.oneusefulthing.org/p/management-as-ai-superpower)** - Effective AI delegation depends on baseline time, success probability and process time: with GPT-5.2 Thinking/Pro, average success 72% on GDPval.
- **[Andrej Karpathy Tweet](https://x.com/karpathy/status/2015883857489522876)** - Karpathy comments on agentic coding as the biggest paradigm shift of the last 20 years: expansion more than acceleration, feeling of what AGI will be.

---

## Business and Society

### Takeaways for AI Engineers

- **Takeaway 1:** The last 12-18 months show Google's catch-up and conquest on all fronts: traffic share from ChatGPT to Gemini (+315%), Apple agreement for 100% smartphone coverage, TPU production with Samsung
- **Takeaway 2:** The AI industry is moving toward much shorter support cycles: the high cost of maintaining old models is pushing rapid retirements like GPT-4o, opening opportunities for enterprise on-premise solutions
- **Takeaway 3:** Apple's moves (Q.ai, Gemini agreement) suggest a strategy focused on AI-human interaction, while Amazon covers half of OpenAI's $100 billion round, potentially bringing GPT to Alexa

- **Action Items:**
  - Evaluate on-premise solutions to stabilize AI models in your enterprise implementations, given the increasingly short support cycles
  - Monitor the evolution of Google's ecosystem (Gemini, TPU Samsung, integrations) which is rapidly eroding OpenAI's dominance on multiple fronts

### What's happening this week?

Always lots of money moving in Silicon Valley. Apple's acquisition of Q.ai (which does vocal systems), together with the agreement with Google for using Gemini that we talked about last week could reveal Cupertino's strategy to focus on AI-human interaction. We'll see.

Amazon, which honestly seems a bit behind (though perhaps its focus is on the cloud that runs AI, where it's anything but behind), appears to be one of the main investors covering half of OpenAI's next $100 billion round. This could be interesting also for OpenAI which, after losing Siri, could see its vocal model land on Alexa.

Meanwhile OpenAI is cutting some costs by retiring GPT-4o and older models. On this it's important to note how the high cost of keeping old models alive is pushing the industry toward much shorter support cycles compared to previous technologies. The need to have more stable models, once desired performance is reached, could push the enterprise market to evaluate on-premise solutions.

I close this section with the analysis of how the last 12-18 months have been a great catch-up and then conquest by Google on all fronts: many percentage points of chatbot traffic are shifting from ChatGPT to Gemini, Apple agreement brings Gemini (obviously already present on Android) to practically 100% of smartphones, the Samsung agreement for TPU production removes them from competition with Nvidia for TSMC production slots accelerating also on that front. And these days there's the rumor that it will soon be possible to import into Gemini the conversations had with ChatGPT (actually it's already possible, but requires being a bit of a tinkerer... now it becomes a button), with the intent to break down the last resistance of users to abandon "the first to arrive" to avoid losing their chat history.

### This week's links

- **[Amazon could invest up to $50 billion in OpenAI in coming weeks, source says](https://www.cnbc.com/2026/01/29/amazon-openai-investment-jassy-altman.html)** - Amazon in talks for $50 billion in OpenAI, potential use of Amazon AI chips, despite previous investments in Anthropic.
- **[Apple Acquires Q.ai](https://techcrunch.com/2026/01/29/apple-buys-israeli-startup-q-ai-as-the-ai-race-heats-up/)** - Apple acquires Israeli startup Q.ai specializing in audio AI to advance whispered speech recognition and enhancement for AirPods and Vision Pro.
- **[Google Trusting Samsung for AI TPU Manufacturing](https://www.sammyfans.com/2025/12/25/google-trusting-samsung-for-ai-tpu-manufacturing/)** - Google entrusts Samsung with AI TPU chip production, strategic partnership in ML semiconductor sector and supply chain diversification.
- **[Retiring GPT-4o and Older Models](https://openai.com/blog/retiring-gpt-4o)** - GPT-4o, GPT-4.1, GPT-4.1 mini retired on February 13 to streamline capabilities and transition toward GPT-5, no simultaneous API changes.
- **[ChatGPT Traffic Analysis: Lead Shrinks as Gemini Surges](https://ppc.land/chatgpts-lead-shrinks-as-gemini-surges-in-ai-traffic-war/)** - ChatGPT dropped from 86.6% to 64.6% in 12 months (-22 pp), Gemini exploded from 5.3% to 22% (+315%), AI market trend reversal.

