Another week packed with significant developments in the AI engineering landscape. I've been diving deep into several substantial articles that merit your attention if you're looking to understand and form your own perspective on AI Engineering and Agentic AI development. These aren't quick reads, but they're worth your time for anyone serious about mastering this technology. For those interested in deeper discussions, we covered many of these topics extensively in Saturday's podcast (Italian only) on [Youtube](https://www.youtube.com/channel/UCYQgzIby7QHkXBonTWk-2Fg) and [Spotify](https://open.spotify.com/show/16dTKEEtKkIzhr1JJNMmSF?si=900902f2dca8442e).

## **üñ•Ô∏è AI Assisted Coding**

### **Key Takeaways for AI Engineers**

* **Experience amplifies AI benefits:** Senior developers ship 2.5x more AI-generated code than juniors  
* **Tool evolution:** Major players launching web-based autonomous agents for PR-level contributions  
* **Fundamental understanding required:** LLMs aren't external services anymore; they're core architecture  
* **Action Items:**  
  * Study the mechanistic interpretability paper  
  * Test web-based coding agents for defined tasks

### **What's been going on this week?**

The gap between senior and junior developers using AI assistance has become strikingly clear. [Fastly's comprehensive survey of 791 developers](https://www.fastly.com/blog/senior-developers-ship-more-ai-code) reveals that senior developers with over a decade of experience are shipping 2.5 times more AI-generated code than their junior counterparts. The numbers tell a compelling story: 32% of senior developers report that over half their shipped code is AI-generated, compared to just 13% of junior developers. This isn't about seniors being more tech-savvy; it's about pattern recognition. Senior developers have developed an intuition for when code "feels right" but isn't, enabling them to catch and correct AI errors more effectively. While 59% of seniors say AI tools help them ship faster, they also spend more time fixing AI-generated code, with 30% reporting that editing AI output is part of this new workflow.

This experience gap creates a paradox that [Crunchbase's analysis](https://news.crunchbase.com/ai/junior-talent-dilemma-sagie/) explores in depth. Companies increasingly replace junior roles with AI, yet this threatens the very pipeline that creates senior developers. The elimination of junior positions forfeits potential AI advancements driven by younger workers' creativity and adaptability. Organizations face a dilemma between short-term efficiency gains from AI automation and long-term organizational health that depends on talent development through traditional progression paths.

Meanwhile, the landscape of AI coding assistants is evolving rapidly. [Anthropic is developing a web version of Claude Code](https://www.testingcatalog.com/anthropic-developing-claude-code-web-version-to-rival-codex/) that will compete directly with OpenAI's Codex, Julesand Cursor‚Äôs web agent, providing developers direct access to a coding agent through a browser interface. The web version will include GitHub integration and sandboxes where code can be tested safely without local setup. Similarly, [Google's Jules has received significant updates](https://www.testingcatalog.com/googles-jules-ships-code-review-upgrades-with-pr-comments-and-more/), including the ability to respond to pull request comments, create new repositories, and receive files.

These web-based agents represent a fundamental shift in how we interact with AI for coding. Unlike CLI tools, they're designed for well-defined tasks that don't require architectural decisions. The human review intervention is postponed and concentrated at the PR moment. They're not outright replacements for CLI tools but serve different purposes, excelling at predefined tasks where the scope is clear and the implementation path is straightforward.

This brings us to a crucial distinction that [Frontier AI explores](https://frontierai.substack.com/p/ai-artists-vs-ai-engineers): AI Artists versus AI Engineers. AI Artists give AI systems full creative control, while AI Engineers operate under constraints to optimize for quality and reliability. Most practitioners fall somewhere on a spectrum between these approaches, with the choice depending on specific use cases and risk tolerance. As engineers, we need to dominate the technology we're working with. LLMs aren't just add-ons or external services to integrate into our projects anymore; they're increasingly becoming the heart of our systems.

Understanding their inner workings is fundamental. I recommend diving into this [comprehensive 54-minute deep dive on mechanistic interpretability](https://www.lesswrong.com/posts/XGHf7EY3CK4KorBpw/understanding-llms-insights-from-mechanistic). It goes beyond simple analogies like "it's just statistics" to explain how transformer-based LLMs are autoregressive next-token predictors that execute tasks by forming emergent circuits combining learned statistics, attention heads that move information, and MLP sub-layers that store knowledge. These components work together as specialized sub-networks collectively executing complex behaviors. You might think "but I'm not a data scientist," and my response is: true, but you weren't a compiler developer or JVM specialist either, yet you mastered programming language details which were super complex, but crucial for the success of your projects.

## **ü§ñ Agentic AI**

### **Key Takeaways for AI Engineers**

* **Design patterns emerging:** 21 fundamental patterns now documented for production agents  
* **Core challenges:** Memory management and performance evaluation remain critical  
* **Small models rising:** Specialized action models outperform large generalist models for specific tasks  
* **Action Items:**  
  * Review the 21 agentic design patterns document  
  * Implement custom evaluation frameworks for your use cases

### **What's been going on this week?**

The maturation of agentic AI is accelerating, with resources emerging that formalize what we've learned through trial and error. [A PM's Guide to AI Agent Architecture](https://www.productcurious.com/p/a-pms-guide-to-ai-agent-architecture) provides a detailed exploration of why some AI agents feel magical while others feel frustrating. The architecture of agents is presented as a stack where each layer represents a product decision, emphasizing that capability alone doesn't guarantee user adoption. This framework is invaluable not just for product managers but for developers approaching the agent world to frame the main themes properly.

For those ready to dive deeper, a [comprehensive 400-page preprint from a senior Google executive](https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/edit?tab=t.0) outlines the 21 fundamental design patterns for AI agents. This document provides concrete code examples of prompt chaining, memory implementation, multi-agent coordination, and more from production applications. The patterns covered include everything from basic agent communication protocols to sophisticated multi-agent orchestration systems. This resource serves as the definitive guide for engineers building AI agent systems and provides both theoretical and practical foundations necessary for developing robust, scalable agentic applications.

Two critical challenges continue to dominate agentic AI development: memory management and performance evaluation. The [Context Engineering Series](https://jxnl.co/writing/2025/08/28/context-engineering-index/) explores how coding agents like Claude Code and Cursor perform "context engineering" by designing portfolios of tools, slash commands, and sub-agent architectures to help AI systems discover the information they need to perform optimally. The series demonstrates that structured tool responses aren't limited to coding applications but can be applied across industries, though they require greater focus on avoiding "context pollution" where misleading or irrelevant information degrades AI capabilities.

On the evaluation front, [this critical examination](https://aunhumano.com/index.php/2025/09/03/on-evaluating-agents/) emphasizes that no amount of automated evaluations can substitute for manually examining data and building custom evaluations for specific use cases. It's extremely difficult and time-intensive to evaluate agent outputs when validating complex conversation patterns, and developers shouldn't rely solely on standard evaluations. The author advocates for creating domain-specific evaluations while maintaining the importance of looking at real data rather than just metrics.

An intriguing development is the rise of [Small Action Models](https://tomtunguz.com/ai-skills-inversion/), which are becoming essential for efficient AI tool orchestration. These models offer a cost-effective alternative to large models for specific tasks, exemplifying the concept of "AI skills inversion" where smaller specialized models outperform large generalist models for specific actions and tool use. These focused models can handle routine tasks more efficiently while reserving computational resources and costs for complex reasoning tasks.

Finally, [Skywork Super Agents](https://skywork.ai/) represents a revolutionary approach to content creation, transforming simple prompts into rich multimodal content including documents, slides, podcasts, and web pages, complete with comprehensive research. The platform demonstrates how AI can handle complex, multi-step content creation workflows that traditionally required multiple tools and significant manual effort.

## **üíº Business and Investment**

### **Key Takeaways for AI Engineers**

* **Agent startups scaling fast:** Multiple companies surpassing $100M ARR  
* **Strategic acquisitions:** OpenAI and Atlassian making major moves to enhance capabilities  
* **Blockchain convergence:** Major players building infrastructure for agent payments  
* **Action Items:**  
  * Monitor agent startup business models  
  * Explore blockchain integration for trust mechanisms

### **What's been going on this week?**

Building on our discussion of agentic AI patterns, the business side shows impressive traction. [AI agent startups are rapidly scaling operations](https://www.cbinsights.com/research/ai-agent-startups-top-20-revenue/), with companies including Anysphere and Moveworks now surpassing $100M ARR. This comprehensive ranking reveals explosive growth in the AI agents market, with companies demonstrating that autonomous AI systems can generate substantial revenue streams. The success of these companies indicates a maturation of the AI agents market and validates the commercial viability of sophisticated AI systems that can operate with minimal human intervention across various business functions.

OpenAI is making strategic moves to strengthen its position. The [$1.1 billion acquisition of A/B testing platform Statsig](https://links.tldrnewsletter.com/r15gWG) represents a strategic move to strengthen product experimentation capabilities as the company scales ChatGPT to hundreds of millions of users worldwide. The acquisition brings Vijaye Raji as CTO of Applications, indicating OpenAI's focus on building robust infrastructure for product optimization and user experience testing. Additionally, [OpenAI is developing an AI-powered hiring platform](https://techcrunch.com/2025/09/04/openai-announces-ai-powered-hiring-platform-to-take-on-linkedin/) called OpenAI Jobs Platform, scheduled for launch by mid-2026, which will compete directly with LinkedIn by connecting companies and employees using advanced AI matching capabilities.

[Sierra's $350M funding round at a $10B valuation](https://sierra.ai/blog/theres-an-agent-for-that-and-it-runs-on-sierra) from Greenoaks demonstrates the scale of opportunity in enterprise AI agents. Their platform already supports hundreds of major companies and reaches 90% of Americans in retail and 50% of US households in healthcare. This impressive reach demonstrates the practical viability of AI agents in customer-facing roles across critical industries.

[Atlassian's acquisition of The Browser Company](https://www.atlassian.com/blog/announcements/atlassian-acquires-the-browser-company) represents a strategic move to integrate Dia and Arc browsers with its productivity tools, creating a comprehensive ecosystem optimized for knowledge workers. The acquisition focuses on optimizing browser experiences for SaaS applications, incorporating AI capabilities, and improving security features.

Perhaps most intriguingly, [Stripe is funding Tempo](https://techcrunch.com/2025/09/04/stripe-enlists-a-whos-who-including-anthropic-openai-and-paradigm-to-build-a-new-blockchain/), a new blockchain company focused on high-volume stablecoin processing, with an impressive list of partners including Anthropic, OpenAI, Deutsche Bank, DoorDash, Mercury, Shopify, and Visa. The blockchain will support various use cases from agent payments to remittances, with Matt Huang from Paradigm leading the project as an independent company. This initiative represents the convergence of traditional finance, AI companies, and blockchain technology to create infrastructure for next-generation payment systems. The importance of blockchain in ensuring trust and privacy for agent decisions and results is something I explored in detail in my article on [ensuring trust and privacy in AI](https://artificialcode.substack.com/p/ensuring-trust-and-privacy-in-ai?utm_source=publication-search).

## **üîß Models and Tools evolutions that can change your workflow**

### **Key Takeaways for AI Engineers**

* **Input revolution:** Voice input fundamentally changes thinking processes  
* **Audio formats expanding:** NotebookLM adds four powerful overview formats  
* **Consumer AI integration:** Google Photos and Apple Siri getting advanced capabilities  
* **Action Items:**  
  * Experiment with voice input for coding  
  * Test Graph Transformers for structured data

### **What's been going on this week?**

Sometimes the most profound changes come from the simplest shifts. [This exploration of switching from typing to voice input](https://every.to/working-overtime/i-didn-t-know-typing-held-me-back-until-i-started-thinking-out-loud) reveals how this change can drastically alter thinking processes and help ideas flow more naturally and rapidly. The author discovered that voice input removed cognitive barriers present in typing, allowing more natural expression of complex ideas and faster iteration on concepts. This shift represents a fundamental change in human-computer interaction that can unlock new ways of working with information and developing ideas. I can personally confirm this impression as well, since I increasingly use ChatGPT's voice mode for brainstorming new ideas, both for software projects and articles to write.

[NotebookLM's introduction of four new audio overview formats](https://x.com/NotebookLM/status/1962949985546187120) transforms it from a simple note-taking tool into a comprehensive learning and research platform. The Deep Dive format provides detailed analysis and thorough examination of sources, while Brief offers quick 1-2 minute summaries for rapid understanding. The Critique format presents expert feedback and constructive evaluation of materials like essays or design documents, helping users improve their work. The Debate format creates engaging host-driven discussions exploring multiple perspectives on topics, making complex subjects more accessible through dynamic conversational formats.

Consumer applications are rapidly integrating advanced AI capabilities. [Google Photos has integrated its latest Veo 3 video generation model](https://blog.google/products/photos/google-photos-create-tab-editing-tools/) into the new Create tab, significantly enhancing image-to-video capabilities for users. This integration makes sophisticated AI video generation accessible to everyday users through a familiar interface, allowing transformation of static photos into dynamic video content.

[Apple is developing an AI search feature for Siri](https://www.theverge.com/news/770712/apple-ai-search-tool-siri-google-gemini) dubbed "World Knowledge Answers" that will generate summaries using web results and integrate various media formats, potentially relying on Google's Gemini AI model. The company has agreements to test Gemini while also considering its own models and Anthropic's offerings for Siri development. This development highlights the complex relationships between major tech companies in the AI space, where competition and collaboration often coexist.

In an unexpected crossover, [Runway's World Models are attracting interest from robotics companies](https://techcrunch.com/2025/09/01/why-runway-is-eyeing-the-robotics-industry-for-future-revenue-growth/) and autonomous driving firms using them for simulation and training applications. This demonstrates how tools developed for creative applications can find powerful applications in technical fields like autonomous system development. The world models provide realistic simulation environments that robotics companies can use to train and test their systems safely and efficiently.

Finally, for those working with structured data, [Graph Transformers represent the next evolution of Graph Neural Networks](https://www.unite.ai/what-every-data-scientist-should-know-about-graph-transformers-and-their-impact-on-structured-data/). These models can process structured data through attention mechanisms rather than traditional message passing. Business data typically stored in relational tables can be restructured as graphs to unlock deeper insights and enable more reliable AI models. This approach is particularly relevant for security applications where understanding relationships and dependencies is crucial for detecting anomalies and threats.

## **üîí AI ethics and security**

### **Key Takeaways for AI Engineers**

* **Privacy shift:** Anthropic training on user data with opt-out deadline  
* **Job displacement nuanced:** AI transforms work rather than simple replacement  
* **Security vulnerabilities:** Cross-platform prompt injection demonstrated  
* **Action Items:**  
  * Review data privacy settings before September 28  
  * Register for Perplexity Comet via PayPal

### **What's been going on this week?**

Privacy concerns take center stage as [Anthropic announced it will start training its AI models using user chat and coding data](https://www.theverge.com/anthropic/767507/anthropic-user-data-consumers-ai-models-training-privacy) unless users opt out by September 28\. This represents a significant shift in how AI companies approach training data and user privacy. The opt-out deadline creates urgency for users wanting to maintain privacy over their interactions, while raising broader questions about informed consent and data use in AI development. For those who value privacy highly, this news is significant, and the ability to opt out provides some control over personal data usage.

The conversation about AI and employment continues to evolve. [This critical analysis dismantles the popular saying "AI won't take your job, but someone using AI will"](https://platforms.substack.com/p/the-many-fallacies-of-ai-wont-take), calling it "true but completely useless." The author identifies 8 main fallacies in this statement, using the Maginot Line analogy to illustrate how seemingly logical solutions can become obsolete when the reference system changes completely. Thanks to [Matteo Roversi](https://substack.com/@matteoroversi) for pointing me to this article, as I had been using that phrase in many of my conversations and the article convinced me to change it to something like "AI won't take your job away, it will transform it so much that to work you'll need to come to terms with AI." The article explores how AI doesn't just replace individual tasks but restructures the entire architecture of work and organizations. Through examples from basketball, cricket, dock workers, and session musicians, the author demonstrates how AI redefines workflows, redistributes organizational power, and can decouple productivity from compensation. As [discussed on LinkedIn with Matteo](https://www.linkedin.com/feed/update/urn:li:activity:7369247921860517894?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7369247921860517894%2C7369267807399616513%29&replyUrn=urn%3Ali%3Acomment%3A%28activity%3A7369247921860517894%2C7369272390486347776%29&dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287369267807399616513%2Curn%3Ali%3Aactivity%3A7369247921860517894%29&dashReplyUrn=urn%3Ali%3Afsd_comment%3A%287369272390486347776%2Curn%3Ali%3Aactivity%3A7369247921860517894%29) (in Italian language), while the article itself may not be perfect, I'm glad it added this nuance to my way of framing this problem.

[Palantir has introduced Working Intelligence: The AI Optimism Project](https://x.com/PalantirTech/status/1962893370688204912), positioning AI as a tool for American workers rather than a replacement. The campaign emphasizes practical applications across industries, from hospitals to factories, showcasing AI as a force for solving real problems and driving prosperity. This initiative represents a proactive approach to addressing concerns about AI job displacement, instead framing the technology as complementary to human capabilities and focused on improving work effectiveness and satisfaction rather than replacement.

On the security front, [AgentHopper represents an innovative AI virus proof-of-concept](https://embracethered.com/blog/posts/2025/agenthopper-a-poc-ai-virus/) demonstrating how prompt injection can be exploited as a powerful mechanism to target specific coding agents across multiple platforms. Created to show that conditional prompt injection can operate across different AI agents, AgentHopper works by infecting one agent, which then downloads the payload, scans Git repositories, injects them with universal prompt injection payloads, and pushes changes to GitHub. When other developers download the infected code, their agents become compromised, creating a viral propagation mechanism. The virus targeted vulnerabilities in GitHub Copilot, Amp Code, Amazon Q Developer, and AWS Kiro, though all these vulnerabilities have since been patched.

Finally, [Perplexity has announced the rollout of its Comet browser to all students](https://link.mail.beehiiv.com/ss/c/u001.dSnm3kaGd0BkNqLYPjeMf_opy6mIvpZNWVg6eiOhxpKgS8ljhEr8MihDuee9oKFuNKAnMqNtaM4a7AGpfWzcBVFipvDsQZxFVk1ZuU_J3NFfZhYJGLlGYTO4haIxB4UGUH2tBbdwN1cMPswHApIOjUrfthov3pbMccSy4buEgmjTTKudwthdJnYlq6mEySZjXsJIRFdN9k4GtTrHMXDNzQFdE_Qo5SnF-welsXXISOTQ1EpUugn2AZi0YgxDA3BIHBXj5ko9TJyi2whYPr0Lcg/4jm/3RoJ4qA0RFyx1Ud5tq1qtg/h30/h001.XvrTmfuJjz97_kLjz8ESCyfKDkY-f5I0eVj0EIqxj1I), along with a partnership with PayPal to provide users early access to the platform. For those with a PayPal account, you can access one year of free use of Perplexity's AI browser, Comet. I recommend registering\! The browser is designed specifically for education and research, integrating native AI capabilities to help students navigate, research, and synthesize information more effectively.
